from http.server import BaseHTTPRequestHandler, HTTPServer
import urllib.parse as urlparse
import pandas as pd
from datetime import datetime
import hashlib
import os
import numbers
import json
import requests
import numpy as np

#CONFIG
PORT = 8080

#The console send data to the server every 5 minutes, we try to send the data to the fds
#server everytimes we receive data from the console. If the data is not sent to the fds server
#we save it to a csv file and try to send it again the next time we receive data from the console.
#If the data is not sent to the fds server more than 60 times, we restart the raspberry.

COUNT_FAILED = 0
MAX_FAILED = 60 
DATA_FILE = '/home/recicamet/proxy/data.csv'
#DATA_FILE = './data.csv'

api = "https://my.api.com/proxy"

def convert_to_celsius(fahrenheit):
    try:
        if fahrenheit is not None:
            fahrenheit = float(fahrenheit)  # Convert to float
            return round((fahrenheit - 32) * 5.0 / 9.0, 2)
    except ValueError:
        return None  # Handle case where conversion fails
    return None

def convert_to_kmh(mph):
    try:
        if mph is not None:
            mph = float(mph)  # Convert to float
            return round(mph * 1.60934, 4)
    except ValueError:
        return None
    return None

def convert_to_mm(value):
    try:
        if value is not None:
            value = float(value)  # Convert to float
            return round(value * 25.4, 4)
    except ValueError:
        return None
    return None

def convert_to_mbar(inhg):
    try:
        if inhg is not None:
            inhg = float(inhg)  # Convert to float
            return round(inhg * 33.8639, 4)
    except ValueError:
        return None
    return None


def generate_md5_hash(value):
    return hashlib.md5(value.encode()).hexdigest()

def parse_date(date_string):
    """Convert date to the ISO 8601 format expected by Java."""
    try:
        # Parse date and convert to ISO 8601 format (yyyy-MM-dd'T'HH:mm:ss'Z')
        dt = datetime.strptime(date_string, "%Y-%m-%d %H:%M:%S")

        return dt.isoformat() + 'Z'
    except Exception:
        return None
    
# def parse_string_to_double(string_value):
#     try:
#         return float(string_value)
#     except (ValueError, TypeError):
#         return None

def normalize_date(date_str):
    date = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')
    minute = date.minute - (date.minute % 5)
    date = date.replace(minute=minute, second=0, microsecond=0)
    return date

def save_to_csv(data):
    # Save to CSV using Pandas
    df = pd.read_csv(DATA_FILE)
    _df = pd.DataFrame([data])
    _df = _df.dropna(axis=1, how='all')
    df = pd.concat([df, _df], ignore_index=True)

    # Save the updated DataFrame back to the CSV file
    df.to_csv(DATA_FILE, index=False)


def create_json_object(row):
    # Create a dictionary to match the Java DTO structure, filling missing values with None
    data = {
        "id": None,  # Assuming ID is autogenerated and not provided in CSV
        "date": parse_date(row.get('dateutc', None)),  # Convert to proper Instant format
        "normalizedDate": parse_date(row.get('dateutc', None)),  # Convert to proper Instant format
        "hashMac": row.get('hashMac', None),
        "winddir": row.get('winddir', None),
        "windspeedmph": row.get('windspeedmph', None),
        "windgustmph": row.get('windgustmph', None),
        "maxdailygust": row.get('maxdailygust', None),
        "windgustdir": None,  # Example, missing in CSV
        # "winddirAvg2m": None,  # Example, missing in CSV
        # "windspdmphAvg2m": None,  # Example, missing in CSV
        "winddir_avg10m": row.get('winddir_avg10m', None),
        # "windspdmphAvg10m": parse_string_to_double(row.get('windspdmph_avg10m', None)),

        "eventrainin": row.get('eventrainin', None),
        "tempf": row.get('tempf', None),
        "mode": row.get('mode', None),
        "stationtype": row.get('stationtype', None),
        "uv": row.get('uv', None),
        "uvi": None, 
        "mn5rainin": None, 
        "hourlyrainin2": None,  
        "solarradiation": row.get('solarradiation', None),
        "weeklyrainin": row.get('weeklyrainin', None),
        "battout": row.get('battout', None),
        "battrain": row.get('battrain', None),
        "battin": None, 
        "batt_co2": row.get('batt_co2', None),
        "humidity": row.get('humidity', None),
        "baromrelin": row.get('baromrelin', None),
        "baromabsin": row.get('baromabsin', None),
        "tempinf": row.get('tempinf', None),
        "humidityin": None, 
        "hourlyrainin": row.get('hourlyrainin', None),
        "dailyrainin": row.get('dailyrainin', None),
        "monthlyrainin": row.get('monthlyrainin', None),
        "yearlyrainin": row.get('yearlyrainin', None),
        "feelsLike": None,  
        "dewPoint": None,  
        "station": None  
    }

    data = {k: (None if pd.isna(v) else v) for k, v in data.items()}

    return data

def send_data(data):
    df = pd.read_csv(DATA_FILE)
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    json_data = []
    json_data.append(data)

    for index, row in df.iterrows():
        json_object = create_json_object(row)
        json_data.append(json_object)
    json_payload = json.dumps(json_data)
    # Send to the API
    #print(f'Sending data to {json_payload}')
    headers = {'Content-Type': 'application/json'}
    try:
        response = requests.post(api, headers=headers, data=json_payload)
        print(f"Sending data status: {response.status_code}")
        print(response.text)
        if(response.status_code == 200):
            #Save the data to the csv file header
            df.head(0).to_csv(DATA_FILE, index=False)
            return True
        else:
            return False
    except requests.exceptions.RequestException as e:
        print(f"Error sending data: {e}")
        return False

class RequestHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        global COUNT_FAILED 
        global MAX_FAILED

        parsed_path = urlparse.urlparse(self.path)
        query = urlparse.parse_qs(parsed_path.query)
        if parsed_path.path == '/api/ambientweather/metrics':
            data = {k: v[0] for k, v in query.items()}

            dateutc = data.get('dateutc')
            utc_date = datetime.strptime(dateutc.replace(" ", "T")+".0Z", "%Y-%m-%dT%H:%M:%S.%fZ")

            # Convert parameters
            data['date'] = dateutc.replace(" ", "T") + ".00Z"
            data['normalizedDate'] = str(normalize_date(dateutc)).replace(" ", "T") + ".00Z"
            data['tempf'] = convert_to_celsius(data.get('tempf', None))
            data['tempinf'] = convert_to_celsius(data.get('tempinf', None))
            data['windspeedmph'] = convert_to_kmh(data.get('windspeedmph', None))
            data['windgustmph'] = convert_to_kmh(data.get('windgustmph', None))
            data['monthlyrainin'] = convert_to_mm(data.get('monthlyrainin', None))
            data['yearlyrainin'] = convert_to_mm(data.get('yearlyrainin', None))
            data['weeklyrainin'] = convert_to_mm(data.get('weeklyrainin', None))
            data['hourlyrainin'] = convert_to_mm(data.get('hourlyrainin', None))
            data['dailyrainin'] = convert_to_mm(data.get('dailyrainin', None))
            data['eventrainin'] = convert_to_mm(data.get('eventrainin', None))
            data['baromrelin'] = convert_to_mbar(data.get('baromrelin', None))
            data['baromabsin'] = convert_to_mbar(data.get('baromabsin', None))
            data['hashMac'] = generate_md5_hash(data.get('PASSKEY'))
            data['mode'] = "proxy"

            data['winddir'] = data.get('winddir', None) 
            data['maxdailygust'] = data.get('maxdailygust', None) 
            data['windgustdir'] = data.get('windgustdir', None) 
            # data['winddirAvg2m'] = data.get('winddirAvg2m', None)
            # data['windspdmphAvg2m'] = data.get('windspdmphAvg2m', None) 
            # data['winddirAvg10m'] = data.get('winddir_avg10m', None)
            # data['windspdmphAvg10m'] = data.get('windspdmph_avg10m', None)
            data['stationtype'] = data.get('stationtype', None) 
            data['uv'] = data.get('uv', None)
            data['uvi'] = data.get('uvi', None) 
            data['solarradiation'] = data.get('solarradiation', None)
            data['battout'] = data.get('battout', None) 
            data['battrain'] = data.get('battrain', None)
            data['battin'] = data.get('battin', None)
            data['batt_co2'] = data.get('batt_co2', None)
            data['humidity'] = data.get('humidity', None)
            data['humidityin'] = data.get('humidityin', None)
            data['feelsLike'] = data.get('feelsLike', None)
            data['dewPoint'] = data.get('dewPoint', None)
            #data['station'] = data.get('station', None) 

            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(b'{"success": true}')

            #try to send data to the fds server
            if send_data(data):
                print("Data sent successfully")
                COUNT_FAILED = 0
            else:
                print("Failed to send data")
                save_to_csv(data)
                if(COUNT_FAILED >= MAX_FAILED):
                    print(f"{datetime.today()} :Restarting the raspberry")
                    os.system("sudo reboot")
                    
        else:
            self.send_response(404)
            self.end_headers()

def run(server_class=HTTPServer, handler_class=RequestHandler, port=PORT):
    server_address = ('', port)
    httpd = server_class(server_address, handler_class)
    print(f'Starting httpd server on port {port}...')
    httpd.serve_forever()

if __name__ == "__main__":
    run()
